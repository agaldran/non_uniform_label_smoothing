{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import scipy.stats as stats2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Uniform Label Smoothing for DR grading\n",
    "In this paper, we introduce a new way of manipulating labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy implementation\n",
    "### Standard Label Smoothing:\n",
    "For this to work, we need our labels to be one-hot encoded. For the sake of illustration, let us assume our problem has 5 different classes, and let us fix our label to be `l=2` here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 5\n",
    "l = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can easily one-hot encode such label with a one-liner in `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(l, n_classes):\n",
    "    return np.eye(n_classes)[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = one_hot_encoding(l, n_classes)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in order to implement Label Smoothing, we first need a uniform distribution sampled such that it has the same size as `one_hot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.2, 0.2, 0.2, 0.2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform = np.ones_like(one_hot)/n_classes\n",
    "uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to assign a weight for each of both representations, and the Uniform Label Smoothing scheme is easily built out of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04, 0.04, 0.84, 0.04, 0.04])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.2\n",
    "soft_labels = (1 - alpha)*one_hot + alpha*uniform\n",
    "soft_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in a single function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniform_label_smoothing(l, n_classes, alpha=0.2):\n",
    "    one_hot = one_hot_encoding(l, n_classes)\n",
    "    uniform = np.ones_like(one_hot)/n_classes\n",
    "    return (1 - alpha)*one_hot + alpha*uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04, 0.04, 0.84, 0.04, 0.04])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_uniform_label_smoothing(l, n_classes=5, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Uniform Label Smoothing:\n",
    "The key here is that there is some relationship in the labels that Label Smoothing is ignoring. Namely, a given label is closer to its neighbors than to further away one. Motivated by this, we first build a set of Gaussian distribution samplings, centered at each class, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaussian_label_distribution(n_classes, std=0.5):\n",
    "    CLs = []\n",
    "    for l in range(n_classes):\n",
    "        CLs.append(stats2.norm.pdf(np.arange(n_classes), l, std))\n",
    "    dists = np.stack(CLs, axis=0)\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = get_gaussian_label_distribution(n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can simply access `dist` at the row corresponding to the label we want to smooth, and we are done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.108, 0.798, 0.108, 0.   ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(dist[l], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in a single function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_uniform_label_smoothing(l, n_classes, std=0.5):\n",
    "    dist = get_gaussian_label_distribution(n_classes, std=std)\n",
    "    return dist[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01519465, 0.2186801 , 0.53192304, 0.2186801 , 0.01519465])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_non_uniform_label_smoothing(l, n_classes=5, std = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the difference in a plot. We exaggerate a bit the `alpha` weight in uniform label smoothing and the standard deviation in non-uniform label smoothing to better appreciate what's going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(20,8))\n",
    "ax[0].bar(np.arange(n_classes), get_uniform_label_smoothing(l, n_classes, alpha = 0.57))\n",
    "ax[1].bar(np.arange(n_classes), get_non_uniform_label_smoothing(l, n_classes, std = 0.75))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the above implementation should work for any amount of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch implementation\n",
    "### Standard Label Smoothing:\n",
    "Again, we assume our problem has 5 different classes, and let us fix our label to be `l=2` here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 5\n",
    "l_tens = torch.Tensor([2]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding_torch(l, n_classes):\n",
    "    return torch.zeros(l.size(0), n_classes).to(l.device).scatter_(1, l.view(-1, 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = one_hot_encoding_torch(l_tens, n_classes)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform = torch.ones_like(one_hot)/n_classes\n",
    "uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0400, 0.0400, 0.8400, 0.0400, 0.0400]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.2\n",
    "soft_labels = (1 - alpha)*one_hot + alpha*uniform\n",
    "soft_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniform_label_smoothing_torch(l, n_classes, alpha=0.2):\n",
    "    one_hot = one_hot_encoding_torch(l, n_classes)\n",
    "    uniform = torch.ones_like(one_hot)/n_classes\n",
    "    return (1 - alpha)*one_hot + alpha*uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0400, 0.0400, 0.8400, 0.0400, 0.0400]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_uniform_label_smoothing_torch(l_tens, n_classes=5, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if it works with a batch of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_tens = torch.Tensor([0,1,2,3,4]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8400, 0.0400, 0.0400, 0.0400, 0.0400],\n",
       "        [0.0400, 0.8400, 0.0400, 0.0400, 0.0400],\n",
       "        [0.0400, 0.0400, 0.8400, 0.0400, 0.0400],\n",
       "        [0.0400, 0.0400, 0.0400, 0.8400, 0.0400],\n",
       "        [0.0400, 0.0400, 0.0400, 0.0400, 0.8400]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_uniform_label_smoothing_torch(l_tens, n_classes=5, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = get_uniform_label_smoothing_torch(l_tens, n_classes=5, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(ncols=5, figsize=(20,4))\n",
    "for i in range(n_classes):\n",
    "    ax[i].bar(np.arange(n_classes), batch[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Uniform Label Smoothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_tens = torch.Tensor([2]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_tens.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_uniform_label_smoothing(l_tens, n_classes, std=0.5):\n",
    "    device = l_tens.device\n",
    "    dist = get_gaussian_label_distribution(n_classes, std = std)\n",
    "    if device is not 'cpu':\n",
    "        soft_labels = torch.from_numpy(dist[l_tens.cpu().numpy()]).to(device)\n",
    "    else:\n",
    "        soft_labels = torch.from_numpy(dist[labels.numpy()])\n",
    "    return soft_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6766e-04, 1.0798e-01, 7.9788e-01, 1.0798e-01, 2.6766e-04]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_non_uniform_label_smoothing(l_tens, n_classes=5, std = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if it works with a batch of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_tens = torch.Tensor([0,1,2,3,4]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = get_non_uniform_label_smoothing(l_tens, n_classes=5, std = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(ncols=5, figsize=(20,4))\n",
    "for i in range(n_classes):\n",
    "    ax[i].bar(np.arange(n_classes), batch[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encapsulating the whole thing\n",
    "We will be needing a version of `torch.CrossEntropyLoss()` that can handle one hot encoded labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss_one_hot(logits, target, reduction='mean'):\n",
    "    logp = F.log_softmax(logits, dim=1)\n",
    "    loss = torch.sum(-logp * target, dim=1)\n",
    "    if reduction == 'none':\n",
    "        return loss\n",
    "    elif reduction == 'mean':\n",
    "        return loss.mean()\n",
    "    elif reduction == 'sum':\n",
    "        return loss.sum()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            '`reduction` must be one of \\'none\\', \\'mean\\', or \\'sum\\'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can encapsulate both label smoothing flavors in a single function that will return the appropriate loss function to be used as criterion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_smoothing_criterion(distribution='uniform', alpha=0.1, std =0.5, reduction='mean'):\n",
    "    '''\n",
    "    distribution can be ''uniform' or 'non-uniform'\n",
    "    '''\n",
    "    def _cross_entropy_loss_one_hot(logits, target, reduction='mean'):\n",
    "        logp = F.log_softmax(logits, dim=1)\n",
    "        loss = torch.sum(-logp * target, dim=1)\n",
    "        if reduction == 'none':\n",
    "            return loss\n",
    "        elif reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                '`reduction` must be one of \\'none\\', \\'mean\\', or \\'sum\\'.')\n",
    "    def _get_gaussian_label_distribution(n_classes, std=0.5):\n",
    "        CLs = []\n",
    "        for l in range(n_classes):\n",
    "            CLs.append(stats2.norm.pdf(np.arange(n_classes), l, std))\n",
    "        dists = np.stack(CLs, axis=0)\n",
    "        return dists\n",
    "    \n",
    "    def _one_hot_encoding_torch(l, n_classes):\n",
    "        return torch.zeros(l.size(0), n_classes).to(l.device).scatter_(1, l.view(-1, 1), 1)\n",
    "    \n",
    "    def _label_smoothing_criterion(logits, labels):\n",
    "        n_classes = logits.size(1)\n",
    "        device = logits.device\n",
    "        if distribution == 'uniform':\n",
    "            one_hot = _one_hot_encoding_torch(labels, n_classes)\n",
    "            uniform = torch.ones_like(one_hot)/n_classes\n",
    "            soft_labels =  (1 - alpha)*one_hot + alpha*uniform\n",
    "        elif distribution == 'non-uniform':\n",
    "            dist = _get_gaussian_label_distribution(n_classes, std=std)\n",
    "            if device is not 'cpu':\n",
    "                soft_labels = torch.from_numpy(dist[labels.cpu().numpy()]).to(device)\n",
    "            else:\n",
    "                soft_labels = torch.from_numpy(dist[labels.numpy()])\n",
    "        else:\n",
    "            print('Not implemented')\n",
    "            \n",
    "        loss = _cross_entropy_loss_one_hot(logits, soft_labels.float(), reduction)\n",
    "        return loss\n",
    "    return _label_smoothing_criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_ULS = label_smoothing_criterion(distribution='uniform', alpha=0.1)\n",
    "loss_fn_NULS = label_smoothing_criterion(distribution='non-uniform', std=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.Tensor([4]).long().unsqueeze(dim=0)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_wrong = torch.Tensor([1, 0, 0, 0, 0]).float().unsqueeze(dim=0)\n",
    "logits_better = torch.Tensor([0, 0, 0, 1, 0]).float().unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.8848), tensor(1.8848))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn_ULS(logits_wrong, labels), loss_fn_ULS(logits_better, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2918), tensor(0.2481))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn_NULS(logits_wrong, labels), loss_fn_NULS(logits_better, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using it in your code\n",
    "Simply import from the associated `n_uls.py` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from n_uls import label_smoothing_criterion as ls_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_ULS = ls_loss(distribution='uniform', alpha=0.1)\n",
    "loss_fn_NULS = ls_loss(distribution='non-uniform', std=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.8848), tensor(1.8848))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn_ULS(logits_wrong, labels), loss_fn_ULS(logits_better, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2918), tensor(0.2481))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn_NULS(logits_wrong, labels), loss_fn_NULS(logits_better, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cpu",
   "language": "python",
   "name": "pytorch_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
