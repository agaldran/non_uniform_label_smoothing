{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import scipy.stats as stats2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Uniform Label Smoothing for DR grading\n",
    "In this paper, we introduce a new way of manipulating labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy implementation\n",
    "### Standard Label Smoothing:\n",
    "For this to work, we need our labels to be one-hot encoded. For the sake of illustration, let us assume our problem has 5 different classes, and let us fix our label to be `l=2` here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 5\n",
    "l = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can easily one-hot encode such label with a one-liner in `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(l, n_classes):\n",
    "    return np.eye(n_classes)[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = one_hot_encoding(l, n_classes)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in order to implement Label Smoothing, we first need a uniform distribution sampled such that it has the same size as `one_hot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.2, 0.2, 0.2, 0.2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform = np.ones_like(one_hot)/n_classes\n",
    "uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to assign a weight for each of both representations, and the Uniform Label Smoothing scheme is easily built out of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04, 0.04, 0.84, 0.04, 0.04])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.2\n",
    "soft_labels = (1 - alpha)*one_hot + alpha*uniform\n",
    "soft_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in a single function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniform_label_smoothing(l, n_classes, alpha=0.2):\n",
    "    one_hot = one_hot_encoding(l, n_classes)\n",
    "    uniform = np.ones_like(one_hot)/n_classes\n",
    "    return (1 - alpha)*one_hot + alpha*uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04, 0.04, 0.84, 0.04, 0.04])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_uniform_label_smoothing(l, n_classes=5, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Uniform Label Smoothing:\n",
    "The key here is that there is some relationship in the labels that Label Smoothing is ignoring. Namely, a given label is closer to its neighbors than to further away one. Motivated by this, we first build a set of Gaussian distribution samplings, centered at each class, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaussian_label_distribution(n_classes, std=0.5):\n",
    "    CLs = []\n",
    "    for l in range(n_classes):\n",
    "        CLs.append(stats2.norm.pdf(np.arange(n_classes), l, std))\n",
    "    dists = np.stack(CLs, axis=0)\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = get_gaussian_label_distribution(n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can simply access `dist` at the row corresponding to the label we want to smooth, and we are done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.108, 0.798, 0.108, 0.   ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(dist[l], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in a single function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_uniform_label_smoothing(l, n_classes, std=0.5):\n",
    "    dist = get_gaussian_label_distribution(n_classes, std=std)\n",
    "    return dist[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01519465, 0.2186801 , 0.53192304, 0.2186801 , 0.01519465])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_non_uniform_label_smoothing(l, n_classes=5, std = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the difference in a plot. We exaggerate a bit the `alpha` weight in uniform label smoothing and the standard deviation in non-uniform label smoothing to better appreciate what's going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(20,8))\n",
    "ax[0].bar(np.arange(n_classes), get_uniform_label_smoothing(l, n_classes, alpha = 0.57))\n",
    "ax[1].bar(np.arange(n_classes), get_non_uniform_label_smoothing(l, n_classes, std = 0.75))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the above implementation should work for any amount of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch implementation\n",
    "### Standard Label Smoothing:\n",
    "Again, we assume our problem has 5 different classes, and let us fix our label to be `l=2` here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 5\n",
    "l_tens = torch.Tensor([2]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding_torch(l, n_classes):\n",
    "    return torch.zeros(l.size(0), n_classes).to(l.device).scatter_(1, l.view(-1, 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 1., 0., 0.]]), device(type='cpu'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = one_hot_encoding_torch(l_tens, n_classes)\n",
    "one_hot, one_hot.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 1., 0., 0.]], device='cuda:0'), device(type='cuda', index=0))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = one_hot_encoding_torch(l_tens.to(device), n_classes)\n",
    "one_hot, one_hot.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2000, 0.2000, 0.2000, 0.2000, 0.2000]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform = torch.ones_like(one_hot)/n_classes\n",
    "uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0400, 0.0400, 0.8400, 0.0400, 0.0400]], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.2\n",
    "soft_labels = (1 - alpha)*one_hot + alpha*uniform\n",
    "soft_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniform_label_smoothing_torch(l, n_classes, alpha=0.2):\n",
    "    one_hot = one_hot_encoding_torch(l, n_classes)\n",
    "    uniform = torch.ones_like(one_hot)/n_classes\n",
    "    return (1 - alpha)*one_hot + alpha*uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0400, 0.0400, 0.8400, 0.0400, 0.0400]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_uniform_label_smoothing_torch(l_tens, n_classes=5, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if it works with a batch of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_tens = torch.Tensor([0,1,2,3,4]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8400, 0.0400, 0.0400, 0.0400, 0.0400],\n",
       "        [0.0400, 0.8400, 0.0400, 0.0400, 0.0400],\n",
       "        [0.0400, 0.0400, 0.8400, 0.0400, 0.0400],\n",
       "        [0.0400, 0.0400, 0.0400, 0.8400, 0.0400],\n",
       "        [0.0400, 0.0400, 0.0400, 0.0400, 0.8400]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_uniform_label_smoothing_torch(l_tens, n_classes=5, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = get_uniform_label_smoothing_torch(l_tens, n_classes=5, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(ncols=5, figsize=(20,4))\n",
    "for i in range(n_classes):\n",
    "    ax[i].bar(np.arange(n_classes), batch[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Uniform Label Smoothing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_tens = torch.Tensor([2]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_tens.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_uniform_label_smoothing(l_tens, n_classes, std=0.5):\n",
    "    device = l_tens.device\n",
    "    dist = get_gaussian_label_distribution(n_classes, std = std)\n",
    "    if device is not 'cpu':\n",
    "        soft_labels = torch.from_numpy(dist[l_tens.cpu().numpy()]).to(device)\n",
    "    else:\n",
    "        soft_labels = torch.from_numpy(dist[labels.numpy()])\n",
    "    return soft_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6766e-04, 1.0798e-01, 7.9788e-01, 1.0798e-01, 2.6766e-04]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_non_uniform_label_smoothing(l_tens, n_classes=5, std = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6766e-04, 1.0798e-01, 7.9788e-01, 1.0798e-01, 2.6766e-04]],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_non_uniform_label_smoothing(l_tens.to(device), n_classes=5, std = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if it works with a batch of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_tens = torch.Tensor([0,1,2,3,4]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = get_non_uniform_label_smoothing(l_tens, n_classes=5, std = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(ncols=5, figsize=(20,4))\n",
    "for i in range(n_classes):\n",
    "    ax[i].bar(np.arange(n_classes), batch[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encapsulating the whole thing\n",
    "We will be needing a version of `torch.CrossEntropyLoss()` that can handle one hot encoded labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss_one_hot(logits, target, reduction='mean'):\n",
    "    logp = F.log_softmax(logits, dim=1)\n",
    "    loss = torch.sum(-logp * target, dim=1)\n",
    "    if reduction == 'none':\n",
    "        return loss\n",
    "    elif reduction == 'mean':\n",
    "        return loss.mean()\n",
    "    elif reduction == 'sum':\n",
    "        return loss.sum()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            '`reduction` must be one of \\'none\\', \\'mean\\', or \\'sum\\'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can encapsulate both label smoothing flavors in a single function that will return the appropriate loss function to be used as criterion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_smoothing_criterion(distribution='uniform', alpha=0.1, std =0.5, reduction='mean'):\n",
    "    '''\n",
    "    distribution can be ''uniform' or 'non-uniform'\n",
    "    '''\n",
    "    def _cross_entropy_loss_one_hot(logits, target, reduction='mean'):\n",
    "        logp = F.log_softmax(logits, dim=1)\n",
    "        loss = torch.sum(-logp * target, dim=1)\n",
    "        if reduction == 'none':\n",
    "            return loss\n",
    "        elif reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                '`reduction` must be one of \\'none\\', \\'mean\\', or \\'sum\\'.')\n",
    "    def _get_gaussian_label_distribution(n_classes, std=0.5):\n",
    "        CLs = []\n",
    "        for l in range(n_classes):\n",
    "            CLs.append(stats2.norm.pdf(np.arange(n_classes), l, std))\n",
    "        dists = np.stack(CLs, axis=0)\n",
    "        return dists\n",
    "    \n",
    "    def _one_hot_encoding_torch(l, n_classes):\n",
    "        return torch.zeros(l.size(0), n_classes).to(l.device).scatter_(1, l.view(-1, 1), 1)\n",
    "    \n",
    "    def _label_smoothing_criterion(logits, labels):\n",
    "        n_classes = logits.size(1)\n",
    "        device = logits.device\n",
    "        if distribution == 'uniform':\n",
    "            one_hot = _one_hot_encoding_torch(labels, n_classes)\n",
    "            uniform = torch.ones_like(one_hot)/n_classes\n",
    "            soft_labels =  (1 - alpha)*one_hot + alpha*uniform\n",
    "        elif distribution == 'non-uniform':\n",
    "            dist = _get_gaussian_label_distribution(n_classes, std=std)\n",
    "            if device is not 'cpu':\n",
    "                soft_labels = torch.from_numpy(dist[labels.cpu().numpy()]).to(device)\n",
    "            else:\n",
    "                soft_labels = torch.from_numpy(dist[labels.numpy()])\n",
    "        else:\n",
    "            print('Not implemented')\n",
    "            \n",
    "        loss = _cross_entropy_loss_one_hot(logits, soft_labels.float(), reduction)\n",
    "        return loss\n",
    "    return _label_smoothing_criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_ULS = label_smoothing_criterion(distribution='uniform', alpha=0.1)\n",
    "loss_fn_NULS = label_smoothing_criterion(distribution='non-uniform', std=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.Tensor([4]).long().unsqueeze(dim=0)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_wrong = torch.Tensor([1, 0, 0, 0, 0]).float().unsqueeze(dim=0)\n",
    "logits_better = torch.Tensor([0, 0, 0, 1, 0]).float().unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.8848), tensor(1.8848, device='cuda:0'))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn_ULS(logits_wrong, labels), loss_fn_ULS(logits_better.to(device), labels.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2918), tensor(0.2481, device='cuda:0'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn_NULS(logits_wrong, labels), loss_fn_NULS(logits_better.to(device), labels.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using it in your code\n",
    "Simply import from the associated `n_uls.py` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from n_uls import label_smoothing_criterion as ls_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_ULS = ls_loss(distribution='uniform', alpha=0.1)\n",
    "loss_fn_NULS = ls_loss(distribution='non-uniform', std=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.8848), tensor(1.8848))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn_ULS(logits_wrong, labels), loss_fn_ULS(logits_better, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2918), tensor(0.2481))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn_NULS(logits_wrong, labels), loss_fn_NULS(logits_better, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isic2019",
   "language": "python",
   "name": "isic2019"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
